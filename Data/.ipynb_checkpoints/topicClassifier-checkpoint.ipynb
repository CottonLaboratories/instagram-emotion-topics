{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4a13bc72-42c0-4c92-b653-f18731013049",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JGras\\anaconda3\\Lib\\site-packages\\transformers\\pipelines\\text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import torch\n",
    "import ast\n",
    "\n",
    "classifier = pipeline(\"text-classification\", model=\"chkla/parlbert-topic-german\", return_all_scores=False)\n",
    "\n",
    "df = pd.read_csv('combined_dataset.csv', dtype={'text': str, 'full_name': str, 'user_name': str, 'code': str}, encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4326c539-6764-4e61-b2b8-348e0358d468",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78a1c4da-6774-4080-b18f-45c3e3fa57a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  11%|█         | 1586/14311 [09:44<51:10,  4.14it/s]  Token indices sequence length is longer than the specified maximum sequence length for this model (573 > 512). Running this sequence through the model will result in indexing errors\n",
      "Processing:  11%|█         | 1587/14311 [09:45<1:06:48,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fehler beim Verarbeiten des Textes: The size of tensor a (573) must match the size of tensor b (512) at non-singleton dimension 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  11%|█         | 1606/14311 [09:49<35:05,  6.03it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fehler beim Verarbeiten des Textes: The size of tensor a (556) must match the size of tensor b (512) at non-singleton dimension 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  11%|█▏        | 1642/14311 [09:59<40:02,  5.27it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fehler beim Verarbeiten des Textes: The size of tensor a (528) must match the size of tensor b (512) at non-singleton dimension 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  13%|█▎        | 1837/14311 [10:58<56:37,  3.67it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fehler beim Verarbeiten des Textes: The size of tensor a (534) must match the size of tensor b (512) at non-singleton dimension 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  17%|█▋        | 2386/14311 [13:49<22:20,  8.90it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fehler beim Verarbeiten des Textes: The size of tensor a (525) must match the size of tensor b (512) at non-singleton dimension 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  24%|██▍       | 3502/14311 [19:16<30:26,  5.92it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fehler beim Verarbeiten des Textes: The size of tensor a (546) must match the size of tensor b (512) at non-singleton dimension 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  35%|███▍      | 4964/14311 [25:16<1:26:01,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fehler beim Verarbeiten des Textes: The size of tensor a (538) must match the size of tensor b (512) at non-singleton dimension 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  58%|█████▊    | 8264/14311 [42:29<51:16,  1.97it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fehler beim Verarbeiten des Textes: The size of tensor a (560) must match the size of tensor b (512) at non-singleton dimension 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  58%|█████▊    | 8326/14311 [43:01<44:57,  2.22it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fehler beim Verarbeiten des Textes: The size of tensor a (631) must match the size of tensor b (512) at non-singleton dimension 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  59%|█████▊    | 8380/14311 [43:26<41:16,  2.39it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fehler beim Verarbeiten des Textes: The size of tensor a (536) must match the size of tensor b (512) at non-singleton dimension 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  67%|██████▋   | 9604/14311 [49:24<14:42,  5.33it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fehler beim Verarbeiten des Textes: The size of tensor a (558) must match the size of tensor b (512) at non-singleton dimension 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  68%|██████▊   | 9684/14311 [49:41<11:14,  6.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fehler beim Verarbeiten des Textes: The size of tensor a (560) must match the size of tensor b (512) at non-singleton dimension 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  81%|████████  | 11596/14311 [58:15<31:41,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fehler beim Verarbeiten des Textes: The size of tensor a (612) must match the size of tensor b (512) at non-singleton dimension 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  82%|████████▏ | 11771/14311 [59:50<18:41,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fehler beim Verarbeiten des Textes: The size of tensor a (555) must match the size of tensor b (512) at non-singleton dimension 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  84%|████████▍ | 12042/14311 [1:01:37<13:41,  2.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fehler beim Verarbeiten des Textes: The size of tensor a (593) must match the size of tensor b (512) at non-singleton dimension 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  84%|████████▍ | 12061/14311 [1:01:48<14:55,  2.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fehler beim Verarbeiten des Textes: The size of tensor a (561) must match the size of tensor b (512) at non-singleton dimension 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  84%|████████▍ | 12078/14311 [1:01:55<16:10,  2.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fehler beim Verarbeiten des Textes: The size of tensor a (535) must match the size of tensor b (512) at non-singleton dimension 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  84%|████████▍ | 12086/14311 [1:01:57<08:18,  4.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fehler beim Verarbeiten des Textes: The size of tensor a (579) must match the size of tensor b (512) at non-singleton dimension 1\n",
      "Fehler beim Verarbeiten des Textes: The size of tensor a (551) must match the size of tensor b (512) at non-singleton dimension 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  85%|████████▍ | 12145/14311 [1:02:23<20:16,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fehler beim Verarbeiten des Textes: The size of tensor a (559) must match the size of tensor b (512) at non-singleton dimension 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  85%|████████▍ | 12148/14311 [1:02:23<11:40,  3.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fehler beim Verarbeiten des Textes: The size of tensor a (550) must match the size of tensor b (512) at non-singleton dimension 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  92%|█████████▏| 13221/14311 [1:09:18<04:47,  3.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fehler beim Verarbeiten des Textes: The size of tensor a (692) must match the size of tensor b (512) at non-singleton dimension 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 14311/14311 [1:15:33<00:00,  3.16it/s]\n"
     ]
    }
   ],
   "source": [
    "sequence_to_classify = df[\"text\"]\n",
    "\n",
    "class_probabilities = []\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "# Iteriere über die Sequenz unter Verwendung von tqdm, um den Fortschritt anzuzeigen\n",
    "for text in tqdm(sequence_to_classify, desc=\"Processing\"):\n",
    "    try:\n",
    "        class_probability = classifier(text)\n",
    "        class_probabilities.append(class_probability)\n",
    "    except Exception as e:\n",
    "        print(f\"Fehler beim Verarbeiten des Textes: {e}\")\n",
    "        # Füge einen Platzhalterwert hinzu, um anzuzeigen, dass die Verarbeitung fehlgeschlagen ist\n",
    "        class_probabilities.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "71123449-b111-4d86-aea2-53fea341335f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_data = [{'label': 'Error', 'score': 0}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6b64f8ad-2da4-40d7-9baf-8f4284c2dc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_dicts = [item[0] if item else dummy_data[0] for item in class_probabilities]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5ed7db36-895d-41d8-9448-c289784dda94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14311"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_of_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8703bb25-0f54-4db4-a8a5-d2af9a3a6b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"class_probability\"] = list_of_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "795002db-4690-4286-9140-0484cd3d46dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"combined_dataset_labeled.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3350a65a-6333-44a3-a053-6aecbefee100",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0fd9b288-ccd6-49ac-8fb8-966b7c63ddb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = df['class_probability'].apply(lambda x: x['label'])\n",
    "df['score'] = df['class_probability'].apply(lambda x: x['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a8d4fdfd-6c51-4cc9-b29e-266148d3c963",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"combined_dataset_labeled.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
